# enterprise-local-rag
Built a Local RAG POC using Ollama (nomic-embed-text, phi3:mini) for private, cost-efficient LLM/embeddings, and PGVector for robust, scalable vector storage. The stack uses LangChain and a FastAPI-based API for end-to-end document management and querying.
